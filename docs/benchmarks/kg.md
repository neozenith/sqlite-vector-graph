# Knowledge Graph Benchmarks

End-to-end benchmarks for the knowledge graph pipeline: entity extraction, relation extraction, entity resolution, and graph-augmented retrieval (GraphRAG).

## Sub-categories


### NER Extraction

Compares NER models on entity extraction quality (micro F1) and performance. Evaluated on Gutenberg texts and standard NER benchmark datasets with gold labels.


#### NER Models

| Model | Type | Params | Size | Description | 
|---------|---------|---------|---------|---------|
| **GLiNER small-v2.1** | Zero-shot NER | 166M | 611 MB | Lightweight generalist entity extraction | 
| **GLiNER medium-v2.1** | Zero-shot NER | 209M | 781 MB | Medium-capacity zero-shot NER | 
| **GLiNER large-v2.1** | Zero-shot NER | 459M | 1780 MB | High-capacity zero-shot NER | 
| **NuNerZero** | Zero-shot NER | ~400M | 1800 MB | NumIND zero-shot NER; labels must be lowercase | 
| **GNER-T5 base** | Seq2seq NER | 248M | 990 MB | Generative NER via T5-base (slower, higher quality) | 
| **GNER-T5 large** | Seq2seq NER | 783M | 3100 MB | Generative NER via T5-large | 
| **spaCy en_core_web_lg** | Statistical NER | — | 560 MB | spaCy's large English pipeline | 
| **FTS5** | Keyword matching | — | — | SQLite full-text search as a baseline | 


#### NER Datasets

| Dataset | Source | Description | 
|---------|---------|---------|
| Wealth of Nations (3300) | Project Gutenberg | Literary text chunks (no gold labels — speed only) | 
| [CrossNER (AI)](https://huggingface.co/datasets/DFKI-SLT/cross_ner) | HuggingFace | CrossNER AI domain; BIO-tagged entities | 
| [CrossNER (CoNLL-2003)](https://huggingface.co/datasets/DFKI-SLT/cross_ner) | HuggingFace | CoNLL-2003 via CrossNER; PER, ORG, LOC, MISC | 
| [CrossNER (Literature)](https://huggingface.co/datasets/DFKI-SLT/cross_ner) | HuggingFace | CrossNER literature domain | 
| [CrossNER (Music)](https://huggingface.co/datasets/DFKI-SLT/cross_ner) | HuggingFace | CrossNER music domain | 
| [CrossNER (Politics)](https://huggingface.co/datasets/DFKI-SLT/cross_ner) | HuggingFace | CrossNER politics domain | 
| [CrossNER (Science)](https://huggingface.co/datasets/DFKI-SLT/cross_ner) | HuggingFace | CrossNER science domain | 
| [Few-NERD (supervised)](https://huggingface.co/datasets/DFKI-SLT/few-nerd) | HuggingFace | Fine-grained NER with 66 entity types (supervised split) | 
| [Few-NERD (inter)](https://huggingface.co/datasets/DFKI-SLT/few-nerd) | HuggingFace | Few-NERD inter-domain split | 
| [Few-NERD (intra)](https://huggingface.co/datasets/DFKI-SLT/few-nerd) | HuggingFace | Few-NERD intra-domain split | 



### Relation Extraction

Evaluates relation extraction quality (triple F1) on standard RE benchmark datasets. Uses NER-based entity pair extraction as a crude relation proxy.


#### RE Datasets

| Dataset | Source | Description | 
|---------|---------|---------|
| [DocRED](https://huggingface.co/datasets/thunlp/docred) | HuggingFace | Document-level relation extraction | 
| [WebNLG](https://huggingface.co/datasets/webnlg-challenge/web_nlg) | HuggingFace | RDF triple verbalization and extraction | 
| [CoNLL-04](https://huggingface.co/datasets/DFKI-SLT/conll04) | HuggingFace | Joint entity and relation extraction | 



### Entity Resolution

Evaluates the HNSW blocking + Jaro-Winkler matching + Leiden clustering pipeline on standard ER benchmark datasets.


#### ER Datasets

| Dataset | Source | Description | 
|---------|---------|---------|
| Wealth of Nations (3300) | Project Gutenberg | Literary entity mentions with spelling variations | 
| FEBRL1 | Freely Extensible Biomedical Record Linkage | Synthetic person records with controlled duplication | 



### GraphRAG Retrieval

Measures whether graph expansion after a VSS or BM25 entry point improves retrieval quality.


#### Retrieval Configurations

| Entry Point | Expansion | Description | 
|---------|---------|---------|
| VSS | none / BFS-1 / BFS-2 | Semantic vector search with optional 1-hop or 2-hop graph expansion | 
| BM25 | none / BFS-1 / BFS-2 | FTS5 keyword search with optional graph expansion | 



## Charts

Charts are generated by `python -m benchmarks.harness.cli analyse --category kg`.


### NER Extraction Speed by Model

```plotly
--8<-- "benchmarks/charts/kg_extraction_speed.json"
```


### Entity Count by Model

```plotly
--8<-- "benchmarks/charts/kg_extraction_entity_count.json"
```


### Entity F1 by NER Model

```plotly
--8<-- "benchmarks/charts/ner_entity_f1_by_model.json"
```


### NER Precision vs Recall by Model

```plotly
--8<-- "benchmarks/charts/ner_precision_recall.json"
```


### NER Speed vs Quality (Pareto Frontier)

```plotly
--8<-- "benchmarks/charts/ner_speed_vs_f1.json"
```


### Triple F1 by RE Model

```plotly
--8<-- "benchmarks/charts/re_triple_f1_by_model.json"
```


### RE Speed vs Quality

```plotly
--8<-- "benchmarks/charts/re_speed_vs_f1.json"
```


### Entity Resolution Pairwise F1 by Dataset

```plotly
--8<-- "benchmarks/charts/er_pairwise_f1.json"
```


### GraphRAG Passage Recall by Entry+Expansion

```plotly
--8<-- "benchmarks/charts/graphrag_retrieval_quality.json"
```
